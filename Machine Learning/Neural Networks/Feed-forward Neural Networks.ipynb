{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global x, w, z, y, delta\n",
    "    x = 1 * np.ones(2)\n",
    "    w = [\n",
    "        0.5 * np.ones((3, 2)),\n",
    "        0.5 * np.ones((2, 3)),\n",
    "        0.5 * np.ones((1, 2))\n",
    "    ]\n",
    "    z = [\n",
    "        np.ones(3),\n",
    "        np.ones(2),\n",
    "        np.ones(1)\n",
    "    ]\n",
    "    y = 1 * np.ones(1)\n",
    "\n",
    "    delta = [\n",
    "        np.ones(3),\n",
    "        np.ones(2),\n",
    "        np.ones(1)\n",
    "    ]\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1.]), array([1.5, 1.5]), array([1.5])]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, w, z):\n",
    "    z[0] = np.dot(w[0], x)\n",
    "    for i in range(1, len(w)):\n",
    "        z[i] = np.dot(w[i], z[i-1])\n",
    "    return z\n",
    "\n",
    "forward(x, w, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.25, 0.25, 0.25]), array([0.25, 0.25]), array([0.5])]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward(y, w, z):\n",
    "    delta[-1] = z[-1] - y  # l1/l2?\n",
    "    for i in range(len(w)-1, 0, -1):\n",
    "        delta[i-1] = np.dot(w[i].T, delta[i])\n",
    "    return delta\n",
    "\n",
    "backward(y, w, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.25, 0.25],\n",
       "        [0.25, 0.25],\n",
       "        [0.25, 0.25]]),\n",
       " array([[0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25]]),\n",
       " array([[-0.25, -0.25]])]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update(x, w, z, delta, eta=1):\n",
    "    w[0] -= eta * np.outer(delta[0], x)  # +=?\n",
    "    for i in range(1, len(w)):\n",
    "        w[i] -= eta * np.outer(delta[i], z[i-1])\n",
    "    return w\n",
    "\n",
    "update(x, w, z, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.92790055, 0.92790055, 0.92790055]),\n",
       "  array([1.29149914, 1.29149914]),\n",
       "  array([1.])],\n",
       " [array([3.98829749e-16, 3.98829749e-16, 3.98829749e-16]),\n",
       "  array([4.298195e-16, 4.298195e-16]),\n",
       "  array([1.11022302e-15])],\n",
       " [array([[0.46395027, 0.46395027],\n",
       "         [0.46395027, 0.46395027],\n",
       "         [0.46395027, 0.46395027]]),\n",
       "  array([[0.46395027, 0.46395027, 0.46395027],\n",
       "         [0.46395027, 0.46395027, 0.46395027]]),\n",
       "  array([[0.38714699, 0.38714699]])])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init()\n",
    "\n",
    "for i in range(50):\n",
    "    z = forward(x, w, z)\n",
    "    delta = backward(y, w, z)\n",
    "    w = update(x, w, z, delta, eta=0.1)\n",
    "    #print('z:', z, 'delta:', delta, 'w:', w, sep='\\n')\n",
    "    #print()\n",
    "\n",
    "z, delta, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.92790055, 0.92790055, 0.92790055]),\n",
       " array([1.29149914, 1.29149914]),\n",
       " array([1.])]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(np.array([1, 1]), w, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.85580109, 1.85580109, 1.85580109]),\n",
       " array([2.58299827, 2.58299827]),\n",
       " array([2.])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(np.array([2, 2]), w, z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 权重之和不必为一\n",
    "- 学习率太高时会跑飞\n",
    "- 偏置不是必须的"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global x, w, b, z, y, delta\n",
    "    x = 1 * np.ones(2)\n",
    "    w = [\n",
    "        0.5 * np.ones((3, 2)),\n",
    "        0.5 * np.ones((2, 3)),\n",
    "        0.5 * np.ones((1, 2))\n",
    "    ]\n",
    "    b = [\n",
    "        0.5 * np.ones(3),\n",
    "        0.5 * np.ones(2),\n",
    "        0.5 * np.ones(1)\n",
    "    ]\n",
    "    z = [\n",
    "        np.ones(3),\n",
    "        np.ones(2),\n",
    "        np.ones(1)\n",
    "    ]\n",
    "    y = 1 * np.ones(1)\n",
    "\n",
    "    delta = [\n",
    "        np.ones(3),\n",
    "        np.ones(2),\n",
    "        np.ones(1)\n",
    "    ]\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.5, 1.5, 1.5]), array([2.75, 2.75]), array([3.25])]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, w, z):\n",
    "    z[0] = np.dot(w[0], x) + b[0]\n",
    "    for i in range(1, len(w)):\n",
    "        z[i] = np.dot(w[i], z[i-1]) + b[i]\n",
    "    return z\n",
    "\n",
    "forward(x, w, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.125, 1.125, 1.125]), array([1.125, 1.125]), array([2.25])]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward(y, w, z):\n",
    "    delta[-1] = z[-1] - y\n",
    "    for i in range(len(w)-1, 0, -1):\n",
    "        delta[i-1] = np.dot(w[i].T, delta[i])\n",
    "    return delta\n",
    "\n",
    "backward(y, w, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.625, -0.625],\n",
       "         [-0.625, -0.625],\n",
       "         [-0.625, -0.625]]),\n",
       "  array([[-1.1875, -1.1875, -1.1875],\n",
       "         [-1.1875, -1.1875, -1.1875]]),\n",
       "  array([[-5.6875, -5.6875]])],\n",
       " [array([-0.625, -0.625, -0.625]), array([-0.625, -0.625]), array([-1.75])])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update(x, w, b, z, delta, eta=1):\n",
    "    w[0] -= eta * np.outer(delta[0], x)\n",
    "    b[0] -= eta * delta[0]\n",
    "    for i in range(1, len(w)):\n",
    "        w[i] -= eta * np.outer(delta[i], z[i-1])\n",
    "        b[i] -= eta * delta[i]\n",
    "    return w, b\n",
    "\n",
    "update(x, w, b, z, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "z:\n",
      "[array([1., 1., 1.]), array([1., 1.]), array([1.])]\n",
      "delta:\n",
      "[array([1., 1., 1.]), array([1., 1.]), array([1.])]\n",
      "w:\n",
      "[array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]]), array([[0.5, 0.5, 0.5],\n",
      "       [0.5, 0.5, 0.5]]), array([[0.5, 0.5]])]\n",
      "b\n",
      "[array([0.5, 0.5, 0.5]), array([0.5, 0.5]), array([0.5])]\n",
      "\n",
      "z:\n",
      "[array([1.5, 1.5, 1.5]), array([2.75, 2.75]), array([3.25])]\n",
      "delta:\n",
      "[array([1.125, 1.125, 1.125]), array([1.125, 1.125]), array([2.25])]\n",
      "w:\n",
      "[array([[0.3875, 0.3875],\n",
      "       [0.3875, 0.3875],\n",
      "       [0.3875, 0.3875]]), array([[0.33125, 0.33125, 0.33125],\n",
      "       [0.33125, 0.33125, 0.33125]]), array([[-0.11875, -0.11875]])]\n",
      "b\n",
      "[array([0.3875, 0.3875, 0.3875]), array([0.3875, 0.3875]), array([0.275])]\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    print('z:', z, 'delta:', delta, 'w:', w, 'b', b, sep='\\n')\n",
    "    print()\n",
    "    z = forward(x, w, z)\n",
    "    delta = backward(y, w, z)\n",
    "    w, b = update(x, w, b, z, delta, eta=0.1)\n",
    "\n",
    "print('z:', z, 'delta:', delta, 'w:', w, 'b', b, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([1., 1.]), 1)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = [(Tensor([1., 1.]), 1)]\n",
    "test_data = training_data\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (1): Linear(in_features=3, out_features=2, bias=True)\n",
      "    (2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "tensor([[0.1295]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.870456  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.346312 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "tensor([[0.6537]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.346312  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.216176 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "tensor([[1.2162]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.216176  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.392748 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "tensor([[0.6073]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.392748  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.109145 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "tensor([[1.1091]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.109145  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.432149 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "tensor([[0.5679]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.432149  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.020305 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "tensor([[1.0203]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.020305  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.466040 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "tensor([[0.5340]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.466040  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.054514 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "tensor([[0.9455]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.054514  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.454278 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "tensor([[1.4543]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.454278  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.121867 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "tensor([[0.8781]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.121867  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.335832 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "tensor([[1.3358]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.335832  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.178925 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "tensor([[0.8211]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.178925  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.236871 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "tensor([[1.2369]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.236871  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.227862 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "tensor([[0.7721]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.227862  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.153074 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "tensor([[1.1531]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.153074  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.270285 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "tensor([[0.7297]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.270285  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.081292 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "tensor([[1.0813]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.081292  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.307404 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "tensor([[0.6926]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.307404  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.019181 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "tensor([[1.0192]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.019181  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.340146 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "tensor([[0.6599]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.340146  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.035037 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "tensor([[0.9650]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.035037  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.349609 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "tensor([[1.3496]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.349609  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.085529 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "tensor([[0.9145]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.085529  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.269385 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "tensor([[1.2694]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.269385  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.129610 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "tensor([[0.8704]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.129610  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.200086 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "tensor([[1.2001]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.200086  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.168413 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "tensor([[0.8316]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.168413  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.139679 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "tensor([[1.1397]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.139679  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.202818 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "tensor([[0.7972]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.202818  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.086599 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "tensor([[1.0866]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.086599  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.233523 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "tensor([[0.7665]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.233523  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.039626 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "tensor([[1.0396]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.039626  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.261083 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "tensor([[0.7389]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.261083  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002207 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "tensor([[0.9978]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.002207  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.320999 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "tensor([[1.3210]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.320999  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.041823 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "tensor([[0.9582]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.041823  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.261006 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "tensor([[1.2610]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.261006  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.077048 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "tensor([[0.9230]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.077048  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.208126 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "tensor([[1.2081]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.208126  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.108563 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "tensor([[0.8914]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.108563  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.161195 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "tensor([[1.1612]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.161195  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.136916 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "tensor([[0.8631]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.136916  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.119289 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "tensor([[1.1193]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.119289  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.162552 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "tensor([[0.8374]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.162552  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.081663 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "tensor([[1.0817]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.081663  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.185835 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "tensor([[0.8142]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.185835  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.047712 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "tensor([[1.0477]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.047712  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.207067 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "tensor([[0.7929]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.207067  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.016938 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "tensor([[1.0169]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "loss: 0.016938  [    1/    1]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.226502 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 3),\n",
    "            nn.Linear(3, 2),\n",
    "            nn.Linear(2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "class SubLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return output - target\n",
    "#loss_fn = SubLoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        print(pred, y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"tensor([0.7735])\", Actual: \"tensor([1])\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(DataLoader(test_data)))\n",
    "x, y = x.to(device), y.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    print(f'Predicted: \"{pred[0]}\", Actual: \"{y}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
