# Model List
- 2024-10 [Best LLM for code completion? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1fwigff/best_llm_for_code_completion/)
- 2025-07 [What's the best local LLM for coding? : r/LocalLLM](https://www.reddit.com/r/LocalLLM/comments/1m5rzgf/whats_the_best_local_llm_for_coding/)
  - Deepseek R1
  - Qwen2.5-Coder
- 2025-08 [Best local LLMs to run on a 5090 (32 GB VRAM)? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1n4tshu/best_local_llms_to_run_on_a_5090_32_gb_vram/)

## Uncensored
- 2024-10 [Local Uncensored CJK Translation Models? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1fyu0cz/local_uncensored_cjk_translation_models/)
- 2025-02 [Uncensored model for novel writing : r/ollama](https://www.reddit.com/r/ollama/comments/1iv2r5s/uncensored_model_for_novel_writing/)
- 2025-06 [Current best uncensored model? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1lfpqs6/current_best_uncensored_model/)

## Gemma
- [princeton-nlp/gemma-2-9b-it-SimPO](https://huggingface.co/princeton-nlp/gemma-2-9b-it-SimPO)
  - [JustData/gemma-2-9b-it-SimPO-Q8\_0-GGUF](https://huggingface.co/JustData/gemma-2-9b-it-SimPO-Q8_0-GGUF)
    - ModelScope: [newsletter/gemma-2-9b-it-SimPO-Q8_0-GGUF](https://www.modelscope.cn/models/newsletter/gemma-2-9b-it-SimPO-Q8_0-GGUF)
  - 默认输出比较短，不过审查确实比较少。
  - 中文输出中可能会偶尔混杂英文词。

## Qwen
### Qwen2.5
- QwQ
  - [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B)
    - [huihui-ai/QwQ-32B-abliterated](https://huggingface.co/huihui-ai/QwQ-32B-abliterated)
      - [bartowski/huihui-ai\_QwQ-32B-abliterated-GGU](https://huggingface.co/bartowski/huihui-ai_QwQ-32B-abliterated-GGUF)

### Qwen3
- [Qwen3-Coder](https://qwen.ai/blog?id=qwen3-coder)
  - [Qwen3-Coder-30B-A3B-Instruct](https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct)
  - [Qwen3-Coder-30B-A3B-Instruct-FP8](https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8)
  - [unsloth/Qwen3-Coder](https://huggingface.co/collections/unsloth/qwen3-coder)
    - [unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF](https://modelscope.cn/models/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF)
      - `ollama run modelscope.cn/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF`

  [Qwen3-Coder-30B-A3B released! : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1me2zc6/qwen3coder30ba3b_released/)

  [Qwen3-Coder: How to Run Locally | Unsloth Documentation](https://docs.unsloth.ai/models/qwen3-coder-how-to-run-locally)

Abliterated:
- [mradermacher/Qwen3-30B-A3B-abliterated-erotic-i1-GGUF](https://huggingface.co/mradermacher/Qwen3-30B-A3B-abliterated-erotic-i1-GGUF?not-for-all-audiences=true)
  - [ModelScope](https://modelscope.cn/models/mradermacher/Qwen3-30B-A3B-abliterated-erotic-i1-GGUF)
- [Qwen3-abliterated - a huihui-ai Collection](https://huggingface.co/collections/huihui-ai/qwen3-abliterated)
  - Ollama: [huihui_ai/qwen3-abliterated](https://ollama.com/huihui_ai/qwen3-abliterated)

[Abliterated Qwen3 when? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1kagyta/abliterated_qwen3_when/)

## Mistral
- [mradermacher/Dolphin-Mistral-24B-Venice-Edition-i1-GGUF](https://huggingface.co/mradermacher/Dolphin-Mistral-24B-Venice-Edition-i1-GGUF)
  - ModelScope: [mradermacher/Dolphin-Mistral-24B-Venice-Edition-i1-GGUF](https://www.modelscope.cn/models/mradermacher/Dolphin-Mistral-24B-Venice-Edition-i1-GGUF)
