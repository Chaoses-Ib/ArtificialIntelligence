# Word Embedding
In natural language processing, **word embedding** is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.[^wiki]

> Embeddingåœ¨æ•°å­¦ä¸Šè¡¨ç¤ºä¸€ä¸ªmaping, f: X -> Yï¼Œ ä¹Ÿå°±æ˜¯ä¸€ä¸ªfunctionï¼Œå…¶ä¸­è¯¥å‡½æ•°æ˜¯injectiveï¼ˆå°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„å•å°„å‡½æ•°ï¼Œæ¯ä¸ªYåªæœ‰å”¯ä¸€çš„Xå¯¹åº”ï¼Œåä¹‹äº¦ç„¶ï¼‰å’Œstructure-preserving (ç»“æ„ä¿å­˜ï¼Œæ¯”å¦‚åœ¨Xæ‰€å±çš„ç©ºé—´ä¸ŠX1 < X2,é‚£ä¹ˆæ˜ å°„ååœ¨Yæ‰€å±ç©ºé—´ä¸ŠåŒç† Y1 < Y2)ã€‚é‚£ä¹ˆå¯¹äºword embeddingï¼Œå°±æ˜¯å°†å•è¯wordæ˜ å°„åˆ°å¦å¤–ä¸€ä¸ªç©ºé—´ï¼Œå…¶ä¸­è¿™ä¸ªæ˜ å°„å…·æœ‰injectiveå’Œstructure-preservingçš„ç‰¹ç‚¹ã€‚
> 
> é€šä¿—çš„ç¿»è¯‘å¯ä»¥è®¤ä¸ºæ˜¯å•è¯åµŒå…¥ï¼Œå°±æ˜¯æŠŠXæ‰€å±ç©ºé—´çš„å•è¯æ˜ å°„ä¸ºåˆ°Yç©ºé—´çš„å¤šç»´å‘é‡ï¼Œé‚£ä¹ˆè¯¥å¤šç»´å‘é‡ç›¸å½“äºåµŒå…¥åˆ°Yæ‰€å±ç©ºé—´ä¸­ï¼Œä¸€ä¸ªèåœä¸€ä¸ªå‘ã€‚
> 
> word embeddingï¼Œå°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªæ˜ å°„æˆ–è€…å‡½æ•°ï¼Œç”Ÿæˆåœ¨ä¸€ä¸ªæ–°çš„ç©ºé—´ä¸Šçš„è¡¨è¾¾ï¼Œè¯¥è¡¨è¾¾å°±æ˜¯word representationã€‚
> 
> æ¨å¹¿å¼€æ¥ï¼Œè¿˜æœ‰image embedding, video embedding, éƒ½æ˜¯ä¸€ç§å°†æºæ•°æ®æ˜ å°„åˆ°å¦å¤–ä¸€ä¸ªç©ºé—´[^zhihu]

[^wiki]: [Word embedding - Wikipedia](https://en.wikipedia.org/wiki/Word_embedding)
[^zhihu]: [ä»€ä¹ˆæ˜¯ word embedding? - çŸ¥ä¹](https://www.zhihu.com/question/32275069)

## Libraries
Python:
- Transformers
- [sentence-transformers: State-of-the-Art Text Embeddings](https://github.com/UKPLab/sentence-transformers)
  - Backends: PyTorch, ONNX, OpenVINO
  - [Speeding up Inference --- Sentence Transformers documentation](https://www.sbert.net/docs/sentence_transformer/usage/efficiency.html)

    [Release v3.2.0 - ONNX and OpenVINO backends offering 2-3x speedup; Static Embeddings offering 50x-500x speedups at ~10-20% performance cost - UKPLab/sentence-transformers](https://github.com/UKPLab/sentence-transformers/releases/tag/v3.2.0)

  - [SentenceTransformer API vs. Transformer API + pooling - Issue #405](https://github.com/UKPLab/sentence-transformers/issues/405)

  [SentenceTransformers Documentation --- Sentence Transformers documentation](https://www.sbert.net/)

  [Why do sentence transformers produce slightly different embeddings for the same text? - Stack Overflow](https://stackoverflow.com/questions/77353142/why-do-sentence-transformers-produce-slightly-different-embeddings-for-the-same)

- [fast-sentence-transformers: Simply, faster, sentence-transformers](https://github.com/davidberenstein1957/fast-sentence-transformers)

Rust:
- [rust-bert: Rust native ready-to-use NLP pipelines and transformer-based models (BERT, DistilBERT, GPT2,...)](https://github.com/guillaume-be/rust-bert)
  - tch/ort + rust-tokenizers
  - [rust-sbert: Rust port of sentence-transformers](https://github.com/cpcdoy/rust-sbert)
  - [rust-sentence-transformers: Rust port of https://github.com/UKPLab/sentence-transformers](https://github.com/mladvladimir/rust-sentence-transformers)

- [FastEmbed-rs: Library for generating vector embeddings, reranking in Rust](https://github.com/Anush008/fastembed-rs)
  - ort + tokenizers
  - No built-in GPU support...
  - æ²¡æœ‰æš´éœ² ort çš„å¼‚æ­¥æ¨ç†å’Œç»ˆæ­¢æ¨ç†çš„æ¥å£
  - anyhow

  [fastembed-bench](benches/fastembed-bench/src/main.rs)

  [FastEmbed-rs ğŸ¦€ - Rust library to generate sentence embeddings for your project. : r/rust](https://www.reddit.com/r/rust/comments/17dniwx/fastembedrs_rust_library_to_generate_sentence/)

- Candle
  - [huggingface/text-embeddings-inference: A blazing fast inference solution for text embeddings models](https://github.com/huggingface/text-embeddings-inference)
  - [ShelbyJenkins/candle\_embed: A simple, CUDA or CPU powered, library for creating vector embeddings using Candle and models from Hugging Face](https://github.com/shelbyJenkins/candle_embed)

[Hugging Face embedding models in Rust : r/rust](https://www.reddit.com/r/rust/comments/1eol2nd/hugging_face_embedding_models_in_rust/)
> Iâ€™m the developer of ort, which would be perfect for this use case. Candle and burn are also excellent choices but unfortunately donâ€™t quite match ort in performance or maturity yet.

## Tools
- [WantWords åå‘è¯å…¸](https://wantwords.net/)