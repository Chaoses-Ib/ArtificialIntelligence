# Word Segmentation
[Tokenization and Word Segmentation - IBM Documentation](https://www.ibm.com/docs/en/watson-libraries?topic=tasks-tokenization-word-segmentation)

## Stemming
[Wikipedia](https://en.wikipedia.org/wiki/Stemming)

Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form - generally a written word form.

## Lemmatization
[Wikipedia](https://en.wikipedia.org/wiki/Lemmatization)

Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form.

## Chinese
[ä¸­æ–‡åˆ†è¯è¯¦è§£ï¼šä»è¯å…¸åŒ¹é…åˆ°æ·±åº¦å­¦ä¹ æ–¹æ³• | Erwin Feng Blog](https://allenwind.github.io/blog/8269/)

[å…³äºä¸­æ–‡åˆ†è¯çš„ä¸€å…ƒåˆ†è¯è®¨è®ºï¼ˆä¼˜ç¼ºç‚¹ï¼‰ - å°å‘¨åšå®¢](https://www.css3er.com/p/167.html)

### Libraries
Rust:
- [huggingface/tokenizers: ğŸ’¥ Fast State-of-the-Art Tokenizers optimized for Research and Production](https://github.com/huggingface/tokenizers)
- [rust-tokenizers: High-performance tokenizers for modern language models, including WordPiece, Byte-Pair Encoding (BPE) and Unigram (SentencePiece) models](https://github.com/guillaume-be/rust-tokenizers) (inactive)

Python:
- [jieba](https://github.com/fxsjy/jieba)

#### [ç™¾åº¦ LAC](https://github.com/baidu/lac)
- Python
- C++
- Java

#### [THULAC](http://thulac.thunlp.org/)
ä¸€ä¸ªé«˜æ•ˆçš„ä¸­æ–‡è¯æ³•åˆ†æå·¥å…·åŒ…ã€‚

- [C++](https://github.com/thunlp/THULAC)
- [Python](https://github.com/thunlp/THULAC-Python)

æœ€åæ›´æ–°äº 2018 å¹´ã€‚